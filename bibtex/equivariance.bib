@inproceedings{Deng2021VectorNeurons,
  title        = {Vector Neurons: A General Framework for SO(3)-Equivariant Networks},
  author       = {
    Deng, Congyue and Litany, Or and Duan, Yueqi and Poulenard, Adrien and
    Tagliasacchi, Andrea and Guibas, Leonidas
  },
  year         = 2021,
  month        = {Oct},
  booktitle    = {2021 IEEE/CVF International Conference on Computer Vision (ICCV)},
  pages        = {12180--12189},
  doi          = {10.1109/ICCV48922.2021.01198},
  issn         = {2380-7504},
  abstract     = {
    Invariance and equivariance to the rotation group have been widely
    discussed in the 3D deep learning community for pointclouds. Yet most
    proposed methods either use complex mathematical tools that may limit their
    accessibility, or are tied to specific input data types and network
    architectures. In this paper, we introduce a general framework built on top
    of what we call Vector Neuron representations for creating SO (3)
    -equivariant neural networks for pointcloud processing. Extending neurons
    from 1D scalars to 3D vectors, our vector neurons enable a simple mapping
    of SO (3) actions to latent spaces thereby providing a framework for
    building equivariance in common neural operations â€“ including linear
    layers, non-linearities, pooling, and normalizations. Due to their
    simplicity, vector neurons are versatile and, as we demonstrate, can be
    incorporated into diverse network architecture backbones, allowing them to
    process geometry inputs in arbitrary poses. Despite its simplicity, our
    method performs comparably well in accuracy and generalization with other
    more complex and specialized state-of-the-art methods on classification and
    segmentation tasks. We also show for the first time a rotation equivariant
    reconstruction network. Source code is available at
    https://github.com/FlyingGiraffe/vnn.
  }
}
@inproceedings{Fuchs2020SE3-Transformers,
  title        = {SE(3)-Transformers: 3D Roto-Translation Equivariant Attention Networks},
  author       = {Fuchs, Fabian and Worrall, Daniel and Fischer, Volker and Welling, Max},
  year         = 2020,
  booktitle    = {Advances in Neural Information Processing Systems},
  publisher    = {Curran Associates, Inc.},
  volume       = 33,
  pages        = {1970--1981},
  url          = {
    https://proceedings.neurips.cc/paper/2020/file/15231a7ce4ba789d13b722cc5c955834-Paper.pdf
  },
  editor       = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin}
}
@inproceedings{Worrall2017HarmonicNetworks,
  title        = {Harmonic Networks: Deep Translation and Rotation Equivariance},
  author       = {
    Worrall, Daniel E. and Garbin, Stephan J. and Turmukhambetov, Daniyar and
    Brostow, Gabriel J.
  },
  year         = 2017,
  month        = {July},
  booktitle    = {2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages        = {7168--7177},
  doi          = {10.1109/CVPR.2017.758},
  issn         = {1063-6919},
  abstract     = {
    Translating or rotating an input image should not affect the results of
    many computer vision tasks. Convolutional neural networks (CNNs) are
    already translation equivariant: input image translations produce
    proportionate feature map translations. This is not the case for rotations.
    Global rotation equivariance is typically sought through data augmentation,
    but patch-wise equivariance is more difficult. We present Harmonic Networks
    or H-Nets, a CNN exhibiting equivariance to patch-wise translation and
    360-rotation. We achieve this by replacing regular CNN filters with
    circular harmonics, returning a maximal response and orientation for every
    receptive field patch. H-Nets use a rich, parameter-efficient and fixed
    computational complexity representation, and we show that deep feature maps
    within the network encode complicated rotational invariants. We demonstrate
    that our layers are general enough to be used in conjunction with the
    latest architectures and techniques, such as deep supervision and batch
    normalization. We also achieve state-of-the-art classification on
    rotated-MNIST, and competitive results on other benchmark challenges.
  }
}
@article{Cohen2016SteerableCNNs,
  title        = {Steerable CNNs},
  author       = {Cohen, Taco S. and Welling, Max},
  year         = 2016,
  publisher    = {arXiv},
  doi          = {10.48550/ARXIV.1612.08498},
  url          = {https://arxiv.org/abs/1612.08498},
  copyright    = {arXiv.org perpetual, non-exclusive license},
  keywords     = {
    Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and
    information sciences, FOS: Computer and information sciences
  }
}
